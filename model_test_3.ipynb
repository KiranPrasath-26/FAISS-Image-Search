{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "import torch\n",
    "import cv2\n",
    "import pickle\n",
    "from io import BytesIO\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, ImageFile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing Objects from AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError  \n",
    "\n",
    "#This is if you are using dataset from s3 bucket\n",
    "access_key = ''\n",
    "secret_key = ''\n",
    "bucket_name = ''\n",
    "folder_path = ''\n",
    "\n",
    "s3 = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_objects_page(page):\n",
    "    aws_files = []\n",
    "    if 'Contents' in page:\n",
    "        aws_files.extend([os.path.join(folder_path, os.path.basename(obj[\"Key\"])) for obj in page['Contents'] if \".jpg\" in obj['Key']])\n",
    "    return aws_files\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_files = []\n",
    "page_workers = 8\n",
    "# Use ThreadPoolExecutor to parallelize listing\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=page_workers) as executor:\n",
    "    # List objects in parallel\n",
    "    futures = [executor.submit(list_objects_page, page) for page in tqdm(page_iterator, desc=\"Listing\")]\n",
    "    \n",
    "    # Gather results from all futures\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        aws_files.extend(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the list in a pickle file\n",
    "with open('indexes/aws_file_list.pkl', 'wb') as f:\n",
    "   pickle.dump(aws_files, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ResNet-18 Imagenet1K for generating the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "model = models.resnet18(weights=weights)\n",
    "\n",
    "model.eval()\n",
    "model.fc = nn.Identity()\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_paths_images):\n",
    "    paths, images = zip(*batch_paths_images)\n",
    "    \n",
    "    # Convert images to tensors and stack them\n",
    "    images_tensor = torch.stack([transform(Image.fromarray(img)) for img in images]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_tensors = model(images_tensor)\n",
    "    \n",
    "    embeddings = [(path, out_tensor.cpu().numpy()) for path, out_tensor in zip(paths, out_tensors)]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "download_workers = 4\n",
    "embeddings = []\n",
    "representations = []\n",
    "\n",
    "def download_and_process_batch(batch_paths):\n",
    "    batch_images = []\n",
    "    for path in batch_paths:\n",
    "        response = s3.get_object(Bucket=bucket_name, Key=path)\n",
    "        image_data = response['Body']\n",
    "        img_np_array = np.asarray(bytearray(image_data.read()), dtype=np.uint8)\n",
    "        img = cv2.imdecode(img_np_array, cv2.IMREAD_COLOR)\n",
    "        batch_images.append((path, img))\n",
    "    return process_batch(batch_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelising the download of images and encoding for saving GPU runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_paths_list = [aws_files[i:i + batch_size] for i in range(0,len(aws_files), batch_size)]\n",
    "embeddings = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=download_workers) as download_executor:\n",
    "    for batch_paths in tqdm(batch_paths_list, desc=\"Downloading\"):\n",
    "        batch_futures = []\n",
    "        for path in batch_paths:\n",
    "            future = download_executor.submit(download_and_process_batch, [path])\n",
    "            batch_futures.append(future)\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(batch_futures):\n",
    "            try:\n",
    "                embeddings_list = future.result()\n",
    "                embeddings.extend(embeddings_list)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index_server/indexes/aws_file_list.pkl', 'rb') as f:\n",
    "   aws_files = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index_server/indexes/aws_representations.pkl', 'rb') as f:\n",
    "   aws_rep = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, embeddings = zip(*aws_rep)\n",
    "path = list(path)\n",
    "emb = list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = np.array(embeddings, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the FAISS Index for Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 512\n",
    "ncentroids = 10\n",
    "m = 16\n",
    "quantiser = faiss.IndexFlatL2(dimensions)\n",
    "index = faiss.IndexIVFPQ (quantiser, dimensions ,ncentroids, m , 8) \n",
    "faiss.normalize_L2(emb) \n",
    "index.train(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"indexes/trained.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(emb)\n",
    "faiss.write_index(index,\"indexes/jewel_trained.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"indexes/jewel_trained.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(image):\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    if input_tensor.size()[1] == 3:\n",
    "        with torch.no_grad():\n",
    "            out_tensor = model(input_tensor)\n",
    "        image.close()\n",
    "        return out_tensor.numpy()\n",
    "    else:\n",
    "        image.close()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a target image and test the searh results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3.get_object(Bucket=bucket_name, Key=path[0]) ## change this part to get the target image from the app\n",
    "image_data = response['Body']\n",
    "img_np_array = np.asarray(bytearray(image_data.read()), dtype=np.uint8)\n",
    "target_img = cv2.imdecode(img_np_array, cv2.IMREAD_COLOR)\n",
    "target_rep = encode(Image.fromarray(target_img))\n",
    "display(Image.fromarray(target_img).resize((300,300)))\n",
    "faiss.normalize_L2(target_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "k = 20\n",
    "D, I = index.search(target_rep, k)\n",
    "I = I[0]\n",
    "[path[i] for i in I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(I)):\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=path[I[i]])\n",
    "    image_data = response['Body']\n",
    "    img_np_array = np.asarray(bytearray(image_data.read()), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_np_array, cv2.IMREAD_COLOR)\n",
    "    print(path[I[i]])\n",
    "    display(Image.fromarray(img).resize((200,200)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jewelsearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
